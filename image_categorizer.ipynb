{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9EJqf4T9a_1"
      },
      "source": [
        "<h1 dir=rtl align=center style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "دسته‌یاب تصویر\n",
        "</font>\n",
        "</h1>\n",
        "\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "به پروژه‌ی دوم کالج یادگیری عمیق خوش آمدید! 🥳\n",
        "مجموعه‌داده‌ی این پروژه توسط <a href=\"https://torob.com/\" target=\"_blank\">ترب</a> در اختیار شما قرار گرفته و شامل بخشی از داده‌های واقعی این وب‌سایت است. همان‌طور که می‌دانید ترب یک موتور جست‌وجوی خرید است که اطلاعات هر محصول را از فروشگاه‌های آنلاین مختلف گرد هم آورده و در یک صفحه‌ی واحد نمایش می‌دهد. بنابراین کاربران قادر خواهند بود به‌راحتی محصول موردنظرشان را پیدا کرده و فروشندگان مختلف آن را مقایسه کنند. یکی از مهم‌ترین نیازمندی‌های فنی چنین پلتفرمی، تشخیص خودکار اطلاعات محصولات است، زیرا پالایش دستی این حجم از داده و استخراج اطلاعات از آن‌ها امری بسیار زمان‌گیر و هزینه‌بر خواهد بود. شاید بتوان دسته‌بندی یک محصول را مهم‌ترین اطلاعات آن دانست، زیرا که در جست‌وجوپذیری آن نقش مهمی ایفا می‌کند.  بنابراین در این پروژه به کمک ترب خواهیم آمد و یک مدل یادگیری عمیق طراحی می‌کنیم که بتواند براساس تصویر یک محصول، دسته‌بندی آن را بیابد.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs-csjvO9a_5"
      },
      "source": [
        "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "مجموعه‌داده\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "به‌دلیل حجم بالای مجموعه‌داده نیاز است آن را جداگانه از <a href=\"https://drive.google.com/file/d/1hZK1rshl4dJVEPkUPykU5cZs_ANyTWp-/view?usp=sharing\" target=\"_blank\">این لینک</a> دانلود کرده و فایل‌های داخل آن را استخراج کنید.  توجه داشته باشید که اندازه‌ی مجموعه‌داده حدود ۲۷۰ مگابایت است و اگر قصد دانلود این حجم از داده را ندارید پیشنهاد می‌کنیم از محیط گوگل کولب استفاده کرده و به‌صورت مستقیم با دستور زیر این فایل را روی کولب خود بارگیری کنید.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "`!gdown 1hZK1rshl4dJVEPkUPykU5cZs_ANyTWp-`\n",
        "\n",
        "<details dir=\"rtl\" style=\"direction: rtl;text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<summary dir=\"rtl\" style=\"color:orange\"><b>رفع مشکل عدم امکان دانلود فایل با <code>gdown</code></b></summary>\n",
        "\n",
        "اگر در هنگام دانلود فایل به‌کمک <code>gdown</code> با خطای عدم اجازه‌ی دسترسی مواجه شدید، کافیست کد زیر را اجرا کرده و دوباره امتحان کنید.\n",
        "\n",
        "<span dir=ltr style=\"direction:ltr;\">\n",
        "\n",
        "`!pip install --upgrade --no-cache-dir gdown`\n",
        "\n",
        "</span>\n",
        "</details>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "مجموعه‌داده‌ی این پروژه شامل ۱۱ دسته‌ی محصول مختلف است که تصاویر مربوط به نمونه‌های آموزشی هر دسته در داخل پوشه‌ای با نامی معادل با شناسه‌ی دسته در پوشه‌ی <code>train</code> قرار گرفته است. همچنین تصاویر مربوط به نمونه‌های آزمون در داخل پوشه‌ی <code>test</code> قرار دارد و مدل شما باید بتواند با ورودی گرفتن هر کدام از این تصاویر، دسته‌ی آن را تشخیص دهد.\n",
        "دسته‌های این محصولات و شناسه‌ی هر کدام در جدول زیر آمده است:‌\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<center>\n",
        "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "\n",
        "| <b>شناسه‌ی دسته</b> | <b>عنوان دسته</b> |\n",
        "| :---: | :---: |\n",
        "| <code>0</code> | کاپشن، بارانی و پالتو مردانه |\n",
        "| <code>1</code> | سویشرت و هودی مردانه |\n",
        "| <code>2</code> | ساعت مچی عقربه‌ ای و دیجیتالی |\n",
        "| <code>3</code> | ساعت دیواری، رومیزی و تزیینی |\n",
        "| <code>4</code> | لوازم جانبی ساعت معمولی و هوشمند |\n",
        "| <code>5</code> | سویشرت و هودی خردسال و نوجوان |\n",
        "| <code>6</code> | کاپشن و پالتو خردسال و نوجوان |\n",
        "| <code>7</code> | سویشرت ورزشی مردانه |\n",
        "| <code>8</code> | سویشرت و شلوار ورزشی مردانه |\n",
        "| <code>9</code> | ساک و چرخ خرید |\n",
        "| <code>10</code> | چمدان و ساک |\n",
        "\n",
        "</font>\n",
        "</div>\n",
        "</center>\n",
        "\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "در ابتدا فایل‌های مربوطه را خوانده و نحوه‌ی بارگیری تصاویر مجموعه‌داده را پیاده‌سازی کنید.\n",
        "\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5Zzqq4eO9dOR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e074bb7-4e6a-42d3-e4dd-5140448f4508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1hZK1rshl4dJVEPkUPykU5cZs_ANyTWp-\n",
            "From (redirected): https://drive.google.com/uc?id=1hZK1rshl4dJVEPkUPykU5cZs_ANyTWp-&confirm=t&uuid=97a2e915-fe6f-480f-9449-d49b519c4af7\n",
            "To: /content/data.zip\n",
            "100% 272M/272M [00:06<00:00, 40.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1hZK1rshl4dJVEPkUPykU5cZs_ANyTWp-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oHGMTg5I9a_7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.utils import image_dataset_from_directory\n",
        "from keras.utils import image_dataset_from_directory\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, RandomFlip, RandomRotation, RandomBrightness,RandomZoom,RandomContrast,RandomTranslation\n",
        "from keras.applications.mobilenet_v2 import preprocess_input\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.applications import MobileNetV2\n",
        "from keras import regularizers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "-aN1yGgk_2xN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hkisYNAc9bAB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fa8935e-2344-46a9-b834-0b6af932efdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8829 files belonging to 11 classes.\n",
            "Using 7064 files for training.\n",
            "Found 8829 files belonging to 11 classes.\n",
            "Using 1765 files for validation.\n"
          ]
        }
      ],
      "source": [
        "  # Reading/Loading the dataset files\n",
        "  # 1. Load Dataset\n",
        "  train_data = image_dataset_from_directory(\n",
        "      directory='./train',\n",
        "      labels='inferred',\n",
        "      label_mode='int',\n",
        "      color_mode='rgb',\n",
        "      batch_size=8,\n",
        "      image_size=(224, 224),\n",
        "      shuffle=True,\n",
        "      validation_split=0.2,\n",
        "      subset='training',\n",
        "      seed=42\n",
        "  )\n",
        "\n",
        "  validation_data = image_dataset_from_directory(\n",
        "      directory='./train',\n",
        "      labels='inferred',\n",
        "      label_mode='int',\n",
        "      color_mode='rgb',\n",
        "      batch_size=8,\n",
        "      image_size=(224, 224),\n",
        "      shuffle=False,\n",
        "      validation_split=0.2,\n",
        "      subset='validation',\n",
        "      seed=42\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecYHp_JyAJLd",
        "outputId": "c2af97aa-f9c1-4a37-ce9f-9798abd2cd02"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6eQYY5w9bAC"
      },
      "source": [
        "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "پیش‌پردازش\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "از هرگونه پیش‌پردازشی که فکر می‌کنید به بهبود عملکرد مدل و فرآیند آموزش آن کمک می‌کند بهره ببرید. از جمله کارهایی که شاید در این مرحله به آن نیاز پیدا کنید می‌توان به تغییر اندازه‌ی تصاویر، نرمال‌سازی مقادیر تصاویر، استفاده از تکنیک‌های تقویت داده (داده‌افزایی)، اعمال تابع پیش‌پردازش یک مدل پیش‌آموخته‌ی مشخص و غیره اشاره کرد.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OTeLYJjQ9bAC"
      },
      "outputs": [],
      "source": [
        "# Preprocessing step\n",
        "base_model = MobileNetV2(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(224, 224, 3),\n",
        "    pooling='avg'\n",
        ")\n",
        "data_augmentation = keras.Sequential([\n",
        "    RandomBrightness(0.3),\n",
        "    RandomFlip(\"horizontal\"),\n",
        "    RandomRotation(0.2),\n",
        "    RandomZoom(0.1),\n",
        "    RandomContrast(0.1),\n",
        "    RandomTranslation(0.1, 0.1),\n",
        "])\n",
        "train_data = train_data.map(lambda x, y: (preprocess_input(data_augmentation(x, training=True)), y))\n",
        "validation_data = validation_data.map(lambda x, y: (preprocess_input(x), y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMaOGNR09bAC"
      },
      "source": [
        "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "مدل‌سازی\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "در این پروژه کاملاً دست‌تان باز است تا ساختارهای دلخواه خود را پیاده و آزمایش کنید. می‌توانید یک شبکه‌ی عصبی کانولوشنی طراحی کنید و از تکنیک‌های رایج این نوع شبکه‌ها بهره ببرید تا به مدلی با عملکرد مناسب دست یابید، یا می‌توانید از یک شبکه‌ی پیش‌آموخته کمک گرفته و تصمیم بگیرید که چه لایه‌هایی را به آن اضافه کنید یا چه بخش‌هایی از آن را فریز کرده یا آموزش دهید. همچنین استفاده از تکنیک‌های دیگری که در فصل بهینه‌سازی و هایپرپارامتر آموخته‌اید را فراموش نکنید.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUPbjdnO9bAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f786a9a1-5f08-40d6-eec9-a27625cd2ca3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.5011 - loss: 1.7075"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 208ms/step - accuracy: 0.5012 - loss: 1.7072 - val_accuracy: 0.7773 - val_loss: 0.8980\n",
            "Epoch 2/20\n",
            "\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 157ms/step - accuracy: 0.7096 - loss: 1.0942 - val_accuracy: 0.7615 - val_loss: 0.9881\n",
            "Epoch 3/20\n",
            "\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7478 - loss: 0.9909"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 155ms/step - accuracy: 0.7479 - loss: 0.9909 - val_accuracy: 0.8334 - val_loss: 0.7155\n",
            "Epoch 4/20\n",
            "\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 155ms/step - accuracy: 0.7836 - loss: 0.8902 - val_accuracy: 0.8193 - val_loss: 0.7925\n",
            "Epoch 5/20\n",
            "\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7920 - loss: 0.8480"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 154ms/step - accuracy: 0.7920 - loss: 0.8480 - val_accuracy: 0.8578 - val_loss: 0.6471\n",
            "Epoch 6/20\n",
            "\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.8122 - loss: 0.7689"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 155ms/step - accuracy: 0.8122 - loss: 0.7689 - val_accuracy: 0.8601 - val_loss: 0.6379\n",
            "Epoch 7/20\n",
            "\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8247 - loss: 0.7252"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 158ms/step - accuracy: 0.8247 - loss: 0.7252 - val_accuracy: 0.8822 - val_loss: 0.5739\n",
            "Epoch 8/20\n",
            "\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 153ms/step - accuracy: 0.8386 - loss: 0.6777 - val_accuracy: 0.8765 - val_loss: 0.6005\n",
            "Epoch 9/20\n",
            "\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 155ms/step - accuracy: 0.8391 - loss: 0.6674 - val_accuracy: 0.8731 - val_loss: 0.6128\n",
            "Epoch 10/20\n",
            "\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.8446 - loss: 0.6386"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 154ms/step - accuracy: 0.8446 - loss: 0.6386 - val_accuracy: 0.9150 - val_loss: 0.4449\n",
            "Epoch 11/20\n",
            "\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 152ms/step - accuracy: 0.8568 - loss: 0.6309 - val_accuracy: 0.8958 - val_loss: 0.5141\n",
            "Epoch 12/20\n",
            "\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 154ms/step - accuracy: 0.8523 - loss: 0.6032 - val_accuracy: 0.8941 - val_loss: 0.4972\n",
            "Epoch 13/20\n",
            "\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 154ms/step - accuracy: 0.8735 - loss: 0.5778 - val_accuracy: 0.8952 - val_loss: 0.4948\n",
            "Epoch 14/20\n",
            "\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8748 - loss: 0.5578"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 155ms/step - accuracy: 0.8748 - loss: 0.5578 - val_accuracy: 0.9133 - val_loss: 0.4329\n",
            "Epoch 15/20\n",
            "\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 153ms/step - accuracy: 0.8818 - loss: 0.5293 - val_accuracy: 0.9139 - val_loss: 0.4502\n",
            "Epoch 16/20\n",
            "\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 155ms/step - accuracy: 0.8745 - loss: 0.5423 - val_accuracy: 0.8918 - val_loss: 0.5098\n",
            "Epoch 17/20\n",
            "\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 153ms/step - accuracy: 0.8851 - loss: 0.5262 - val_accuracy: 0.9059 - val_loss: 0.4706\n",
            "Epoch 18/20\n",
            "\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 154ms/step - accuracy: 0.8841 - loss: 0.5067 - val_accuracy: 0.8986 - val_loss: 0.4694\n",
            "Epoch 19/20\n",
            "\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.8871 - loss: 0.4953"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m883/883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 154ms/step - accuracy: 0.8871 - loss: 0.4953 - val_accuracy: 0.9190 - val_loss: 0.4131\n",
            "Epoch 20/20\n",
            "\u001b[1m 47/883\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:57\u001b[0m 141ms/step - accuracy: 0.8835 - loss: 0.5332"
          ]
        }
      ],
      "source": [
        "# Model design\n",
        "base_model.trainable = False  # Freeze all layers initially\n",
        "\n",
        "x = base_model.output\n",
        "# x = BatchNormalization()(x)\n",
        "x = Dense(256, activation='relu', kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4))(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4))(x)\n",
        "x = Dropout(0.4)(x)\n",
        "outputs = Dense(11, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "# 6. Unfreeze Last 20 Layers for Fine-tuning\n",
        "for layer in base_model.layers[-25:]:\n",
        "    layer.trainable = True\n",
        "# Learning rate schedule\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-4,\n",
        "    decay_steps=1000,\n",
        "    decay_rate=0.9,\n",
        "    staircase=True\n",
        ")\n",
        "# 7. Compile the Model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True),\n",
        "    tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "    # tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2, verbose=1)\n",
        "]\n",
        "\n",
        "\n",
        "history_finetune = model.fit(\n",
        "    train_data,\n",
        "    epochs=20,\n",
        "    validation_data=validation_data,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSpKW0jJ9bAD"
      },
      "source": [
        "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "پیش‌بینی\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "در پوشه‌ی <code>test</code> چندین نمونه‌ی آزمون در اختیار شما قرار گرفته و نیاز است مدل شما تا حد ممکن دسته‌بندی هر کدام از آن‌ها را به‌درستی تشخیص دهد. پیشنهاد می‌کنیم برای اطمینان از عملکرد مدل خود و بهبود آن، ابتدا آن را بر روی یک مجموعه‌ی اعتبارسنجی آزمایش کنید.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "\n",
        "<h3 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "معیار ارزیابی\n",
        "</font>\n",
        "</h3>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "هدف این است که مدل شما دسته‌بندی یک محصول را با دقت بالا پیش‌بینی کند، بنابراین در این پروژه از معیار  <code>Accuracy</code> جهت ارزیابی نتایج مدل شما استفاده خواهد شد.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font color=\"red\"><b color='red'>توجه:</b></font>\n",
        "<font face=\"vazir\" size=3>\n",
        " جهت کسب امتیاز کامل نیاز است تا پاسخ شما حداقل امتیاز <code>83</code> را با توجه به معیار معرفی‌شده کسب نماید.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "N6DahTSo9bAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab20e769-5445-4feb-f461-19a91e1190ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8919 - loss: 0.4712\n",
            "Validation Accuracy: 92.52%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate\n",
        "val_loss, val_accuracy = model.evaluate(validation_data, verbose=1)\n",
        "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_DUHsd69bAE"
      },
      "source": [
        "<h3 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "ساختار خروجی برای نمونه‌های آزمون\n",
        "</font>\n",
        "</h3>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        " پیش‌بینی مدل خود را برای نمونه‌های آزمون به‌شکل برچسبی بین ۰ تا ۱۰ تولید کرده و در ستون <code>cat_id</code> یک دیتافریم با نام <code>submission</code> در قالب جدول زیر ذخیره کنید.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<center>\n",
        "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "    \n",
        "|ستون|توضیحات|\n",
        "|:------:|:---:|\n",
        "|<code>image_name</code>|نام فایل تصویر (مشابه با نمونه‌ی آزمون)|\n",
        "|<code>cat_id</code>|برچسب/شناسه‌ی دسته (پیش‌بینی مدل)|\n",
        "    \n",
        "</font>\n",
        "</div>\n",
        "</center>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font color=\"red\"><b color='red'>توجه:</b></font>\n",
        "<font face=\"vazir\" size=3>\n",
        "در تبدیل خروجی مدل به برچسب‌ها توجه داشته باشید که اگر از تابع <code>image_dataset_from_directory</code> جهت خواندن تصاویر استفاده کرده‌اید، ترتیب برچسب‌ها به آن شکلی نیست که انتظارش را داریم و به شکل زیر خواهد بود. بنابراین خروجی نورون سوم برابر پیش‌بینی برچسب ۱۰ است و نه ۲! پس اگر روی خروجی مدل تابع <code>np.argmax</code> اعمال کنید برچسب‌های درستی تولید نمی‌شود. این موضوع یکی از چالش‌های رایج در پروژه‌های دسته‌بندی تصویر است که مشاهده می‌کنیم مدل روی داده‌های آموزشی و اعتبارسنجی به‌خوبی عمل می‌کند اما در زمان آزمون عملکرد بسیار بدی از خود نشان می‌دهد و شوکه می‌شویم. دلیلش این است که نگاشت خروجی به برچسب را به‌درستی انجام نداده‌ایم.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "`['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9']`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cSD3SwaJ9bAE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11380a8c-fb71-40d4-8a2b-6c2c9c490aa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1201 files.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step\n",
            "             image_name  cat_id\n",
            "0  -56lhw2AKjYI0Hnt.jpg       0\n",
            "1  -6OdHXCBItIArPyk.jpg       2\n",
            "2  -7241lsvPiVpNVFV.jpg       9\n",
            "3  -8-0wltLEZBDTM5M.jpg       9\n",
            "4  -GcrzANWUmrjk2tb.jpg       8\n"
          ]
        }
      ],
      "source": [
        "# Preparing submission file\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    directory='./test',\n",
        "    labels=None,\n",
        "    image_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    shuffle=False\n",
        ")\n",
        "file_paths = test_dataset.file_paths\n",
        "image_names = [os.path.basename(path) for path in file_paths]\n",
        "test_dataset = test_dataset.map(lambda x: preprocess_input(x))\n",
        "predicted_labels = model.predict(test_dataset)\n",
        "\n",
        "mapping = {\n",
        "    0: 0,\n",
        "    1: 1,\n",
        "    2: 10,\n",
        "    3: 2,\n",
        "    4: 3,\n",
        "    5: 4,\n",
        "    6: 5,\n",
        "    7: 6,\n",
        "    8: 7,\n",
        "    9: 8,\n",
        "    10: 9\n",
        "}\n",
        "predicted_labels_mapped = np.argmax(predicted_labels, axis=1)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'image_name': image_names,\n",
        "    'cat_id': predicted_labels_mapped\n",
        "}) # TODO\n",
        "submission\n",
        "mapped_labels = [mapping[label] for label in predicted_labels_mapped]\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'image_name': image_names,\n",
        "    'cat_id': mapped_labels\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(submission.head())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MF05eyB9bAE"
      },
      "source": [
        "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "<b>سلول جواب‌ساز</b>\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "    برای ساخته‌شدن فایل <code>result.zip</code> سلول زیر را اجرا کنید. توجه داشته باشید که پیش از اجرای سلول زیر تغییرات اعمال شده در نت‌بوک را ذخیره کرده باشید (<code>ctrl+s</code>) تا در صورت نیاز به پشتیبانی امکان بررسی کد شما وجود داشته باشد.</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "beA07J9I9bAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bd78775-06d3-4027-aaab-8a3d5e784636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Paths:\n",
            "['image_categorizer.ipynb', 'submission.csv']\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import joblib\n",
        "\n",
        "def compress(file_names):\n",
        "    print(\"File Paths:\")\n",
        "    print(file_names)\n",
        "    compression = zipfile.ZIP_DEFLATED\n",
        "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
        "        for file_name in file_names:\n",
        "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "file_names = ['image_categorizer.ipynb', 'submission.csv']\n",
        "compress(file_names)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}